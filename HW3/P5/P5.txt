Part 1:
Finished after 911 iterations, 214.33168 ms total, 0.235270779363 ms per iteration
Found 2 regions

Finished after 531 iterations, 124.05312 ms total, 0.233621694915 ms per iteration
Found 35 regions

Part 2:
Finished after 529 iterations, 133.35928 ms total, 0.252096937618 ms per iteration
Found 2 regions

Finished after 269 iterations, 68.04856 ms total, 0.252968624535 ms per iteration
Found 35 regions

Part 3:
Finished after 8 iterations, 2.59184 ms total, 0.32398 ms per iteration
Found 2 regions

Finished after 8 iterations, 2.4332 ms total, 0.30415 ms per iteration
Found 35 regions

Part 5:
If instead of atomic_min() we use min(), then the update step is not done in a single transaction, meaning between
the min() check and the subsequent update, a different thread could update the reference value. Suppose this
different thread actually updated the reference to an even lower value than what we had intended. Now, if we go ahead
 with our update, we are actually *increasing* the reference value. It could therefore also lead to an increase in
 this value between iterations.

 So while it would be faster to do without atomic_min() as memory access is not serialized, it is also slow since it
 means more iterations have to be performed. While empirical testing is needed to determine which is the better
 trade-off, my sense is that for simple, low-iteration mazes, atomic_min() is going to present a significant overhead
  so it might be better to do a few more iterations. The opposite is likely true for high-iteration mazes.

This makes things more inefficient since this cache is potentially being updated with worse values. However, because
ultimately the stopping condition is whether or not any more updates have been performed, it won't effect the
correctness of the algorithm.